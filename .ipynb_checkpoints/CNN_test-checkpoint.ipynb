{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963dfeba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_37876/1002061816.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv('merged_data.csv')\n",
    "result = data[data[\"name\"].str.contains(\"kuba\")]\n",
    "result_train = data[data[\"name\"].str.contains(\"kuba\") == False]\n",
    "\n",
    "result_train.drop('name', axis=1, inplace=True)\n",
    "result.drop('name', axis=1, inplace=True)\n",
    "\n",
    "X_train = result_train.iloc[:, :-1].values\n",
    "labels_train = result_train.iloc[:, -1].values\n",
    "\n",
    "X_test = result.iloc[:, :-1].values\n",
    "labels_test = result.iloc[:, -1].values\n",
    "#print(labels_train)\n",
    "#print(labels_test)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "\n",
    "labels_train1 = encoder.fit_transform(labels_train)\n",
    "print(labels_train1)\n",
    "\n",
    "labels_test1 = encoder.transform(labels_test)\n",
    "print(labels_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35a5e5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m\n\u001b[0;32m      6\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_test)\u001b[38;5;241m.\u001b[39mreshape(X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#for n in range(len(X_train)):\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#X_train=np.asarray(X_train).astype(np.int)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#X_train = X_train.ravel()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#X_test = np.asarray(X_test).ravel()\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#for n in range(len(X_test)):\u001b[39;00m\n\u001b[0;32m     12\u001b[0m    \u001b[38;5;66;03m# X_test[n]=np.asarray(X_test[n]).astype(np.int)\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m [\u001b[38;5;28mprint\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape, i\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39minputs]\n\u001b[0;32m     16\u001b[0m [\u001b[38;5;28mprint\u001b[39m(o\u001b[38;5;241m.\u001b[39mshape, o\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39moutputs]\n\u001b[0;32m     17\u001b[0m [\u001b[38;5;28mprint\u001b[39m(l\u001b[38;5;241m.\u001b[39mname, l\u001b[38;5;241m.\u001b[39minput_shape, l\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPool1D, Dropout\n",
    "\n",
    "\n",
    "X_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "#for n in range(len(X_train)):\n",
    "#X_train=np.asarray(X_train).astype(np.int)\n",
    "#X_train = X_train.ravel()\n",
    "#X_test = np.asarray(X_test).ravel()\n",
    "#for n in range(len(X_test)):\n",
    "   # X_test[n]=np.asarray(X_test[n]).astype(np.int)\n",
    "\n",
    "    \n",
    "[print(i.shape, i.dtype) for i in model.inputs]\n",
    "[print(o.shape, o.dtype) for o in model.outputs]\n",
    "[print(l.name, l.input_shape, l.dtype) for l in model.layers]\n",
    "    \n",
    "print(\"X Train shape: \", X_train.shape)\n",
    "print(\"X Test shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22631e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 500, 32)           128       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 500, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 500, 128)          24704     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 250, 128)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 250, 128)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               4096128   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,131,560\n",
      "Trainable params: 4,131,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 34\u001b[0m\n\u001b[0;32m     29\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     31\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m---> 34\u001b[0m [\u001b[38;5;28mprint\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape, i\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39minputs]\n\u001b[0;32m     35\u001b[0m [\u001b[38;5;28mprint\u001b[39m(o\u001b[38;5;241m.\u001b[39mshape, o\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39moutputs]\n\u001b[0;32m     36\u001b[0m [\u001b[38;5;28mprint\u001b[39m(l\u001b[38;5;241m.\u001b[39mname, l\u001b[38;5;241m.\u001b[39minput_shape, l\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Create sequential model \n",
    "cnn_model = tf.keras.models.Sequential()\n",
    "\n",
    "#First CNN layer  with 32 filters, conv window 3, relu activation and same padding\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001), input_shape = (X_train.shape[1],1)))\n",
    "\n",
    "#Second CNN layer  with 64 filters, conv window 3, relu activation and same padding\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "\n",
    "#Third CNN layer with 128 filters, conv window 3, relu activation and same padding\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "\n",
    "#Fourth CNN layer with Max pooling\n",
    "cnn_model.add(MaxPool1D(pool_size=(3,), strides=2, padding='same'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "\n",
    "#Flatten the output\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "#Add a dense layer with 256 neurons\n",
    "cnn_model.add(Dense(units = 128, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "\n",
    "#Add a dense layer with 512 neurons\n",
    "cnn_model.add(Dense(units = 32, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "\n",
    "#Softmax as last layer with five outputs\n",
    "cnn_model.add(Dense(units = 8, activation='softmax'))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.summary()\n",
    "\n",
    "\n",
    "[print(i.shape, i.dtype) for i in model.inputs]\n",
    "[print(o.shape, o.dtype) for o in model.outputs]\n",
    "[print(l.name, l.input_shape, l.dtype) for l in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1b685415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(X_train), type(X_test), type(labels_train), type(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d0bc1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"C:\\Users\\micha\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\micha\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\micha\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\micha\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"C:\\Users\\micha\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_9180\\1833644091.py\", line 1, in <module>\n      cnn_model_history = cnn_model.fit(X_train, labels_train1, epochs=10, batch_size =5, validation_data = (X_test, labels_test1))\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2084, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5630, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [1,8] and labels shape [8]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1106]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cnn_model_history \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_train1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_test1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"C:\\Users\\micha\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\micha\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\micha\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\micha\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"C:\\Users\\micha\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_9180\\1833644091.py\", line 1, in <module>\n      cnn_model_history = cnn_model.fit(X_train, labels_train1, epochs=10, batch_size =5, validation_data = (X_test, labels_test1))\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2084, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"C:\\Users\\micha\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5630, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [1,8] and labels shape [8]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1106]"
     ]
    }
   ],
   "source": [
    "\n",
    "cnn_model_history = cnn_model.fit(X_train, labels_train1, epochs=10, batch_size =1, validation_data = (X_test, labels_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73baa2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mag_1     mag_2     mag_3     mag_4     mag_5     mag_6     mag_7  \\\n",
      "0     0.265739  0.256914  0.238871  0.204497  0.183374  0.212214  0.244017   \n",
      "1     0.126638  0.063612  0.041273  0.050787  0.060859  0.076889  0.067438   \n",
      "2     0.074331  0.042567  0.033469  0.047282  0.054843  0.064086  0.074341   \n",
      "3     0.059915  0.051223  0.044134  0.036096  0.034211  0.040493  0.040402   \n",
      "4     0.009380  0.005115  0.017383  0.015676  0.014560  0.037761  0.094945   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2157  0.287983  0.239614  0.209854  0.181102  0.164073  0.191248  0.221496   \n",
      "2158  0.129129  0.117114  0.112617  0.108116  0.110345  0.141989  0.174905   \n",
      "2159  0.297354  0.237052  0.185462  0.152254  0.140301  0.168356  0.198901   \n",
      "2160  0.196470  0.169514  0.152267  0.134577  0.124661  0.147093  0.170851   \n",
      "2161  0.292884  0.253282  0.222732  0.200584  0.200503  0.259909  0.322702   \n",
      "\n",
      "         mag_8     mag_9    mag_10  ...   mag_493   mag_494   mag_495  \\\n",
      "0     0.270322  0.241667  0.244714  ...  0.177693  0.101413  0.047730   \n",
      "1     0.047884  0.022487  0.014918  ...  0.038617  0.038532  0.029333   \n",
      "2     0.080385  0.077601  0.089682  ...  0.074950  0.061139  0.063550   \n",
      "3     0.040209  0.045557  0.058400  ...  0.002198  0.005624  0.011659   \n",
      "4     0.138455  0.130802  0.111539  ...  0.069950  0.056171  0.063321   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2157  0.249034  0.223716  0.215298  ...  0.102798  0.078374  0.080415   \n",
      "2158  0.201326  0.179670  0.170672  ...  0.221865  0.177014  0.177445   \n",
      "2159  0.225881  0.209218  0.215588  ...  0.196581  0.150541  0.151612   \n",
      "2160  0.190234  0.166930  0.156963  ...  0.157541  0.131936  0.145671   \n",
      "2161  0.362787  0.303066  0.259426  ...  0.175841  0.151296  0.170315   \n",
      "\n",
      "       mag_496   mag_497   mag_498   mag_499   mag_500    name    activity  \n",
      "0     0.055375  0.173566  0.252127  0.178366  0.148060   karol  downstairs  \n",
      "1     0.056244  0.075426  0.078247  0.065877  0.076159   karol  downstairs  \n",
      "2     0.042444  0.030385  0.016828  0.016744  0.042866   karol  downstairs  \n",
      "3     0.015238  0.016284  0.012956  0.011287  0.012326   karol  downstairs  \n",
      "4     0.079940  0.108805  0.119693  0.096210  0.112591   karol  downstairs  \n",
      "...        ...       ...       ...       ...       ...     ...         ...  \n",
      "2157  0.088126  0.103586  0.098664  0.078491  0.099228  wiktor     walking  \n",
      "2158  0.190307  0.213598  0.205722  0.173344  0.236482  wiktor     walking  \n",
      "2159  0.165121  0.188219  0.173101  0.131441  0.159511  wiktor     walking  \n",
      "2160  0.173773  0.217158  0.218553  0.179803  0.230617  wiktor     walking  \n",
      "2161  0.202021  0.240609  0.223764  0.166183  0.192213  wiktor     walking  \n",
      "\n",
      "[2162 rows x 502 columns]\n"
     ]
    }
   ],
   "source": [
    "da = pd.read_csv('merged_data_normalized.csv')\n",
    "print(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae3a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
