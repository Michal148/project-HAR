{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963dfeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv('merged_data.csv')\n",
    "result = data[data[\"name\"].str.contains(\"kuba\")]\n",
    "result_train = data[data[\"name\"].str.contains(\"kuba\") == False]\n",
    "\n",
    "result_train.drop('name', axis=1, inplace=True)\n",
    "result.drop('name', axis=1, inplace=True)\n",
    "\n",
    "X_train = result_train.iloc[:, :-1].values\n",
    "labels_train = result_train.iloc[:, -1].values\n",
    "\n",
    "X_test = result.iloc[:, :-1].values\n",
    "labels_test = result.iloc[:, -1].values\n",
    "#print(labels_train)\n",
    "#print(labels_test)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "\n",
    "labels_train1 = encoder.fit_transform(labels_train)\n",
    "print(labels_train1)\n",
    "\n",
    "labels_test1 = encoder.transform(labels_test)\n",
    "print(labels_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d9f8916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features shape (1269, 115)\n",
      "Actual labels shape (1269, 8)\n"
     ]
    }
   ],
   "source": [
    "print('Input features shape', X_test.shape)\n",
    "print('Actual labels shape', labels_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35a5e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train shape:  (3687, 115, 1)\n",
      "X Test shape:  (1269, 115, 1)\n",
      "Y Train shape:  (3687, 8)\n",
      "Y Test shape:  (1269, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPool1D, Dropout\n",
    "\n",
    "\n",
    "X_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "# labels_train1 = np.array(labels_train1).reshape(labels_train1.shape[0], labels_train1.shape[1], 1)\n",
    "# labels_test1 = np.array(labels_test1).reshape(labels_test1.shape[0], labels_test1.shape[1], 1)\n",
    "#for n in range(len(X_train)):\n",
    "#X_train=np.asarray(X_train).astype(np.int)\n",
    "#X_train = X_train.ravel()\n",
    "#X_test = np.asarray(X_test).ravel()\n",
    "#for n in range(len(X_test)):\n",
    "   # X_test[n]=np.asarray(X_test[n]).astype(np.int)\n",
    "\n",
    "    \n",
    "# [print(i.shape, i.dtype) for i in model.inputs]\n",
    "# [print(o.shape, o.dtype) for o in model.outputs]\n",
    "# [print(l.name, l.input_shape, l.dtype) for l in model.layers]\n",
    "    \n",
    "print(\"X Train shape: \", X_train.shape)\n",
    "print(\"X Test shape: \", X_test.shape)\n",
    "print(\"Y Train shape: \", labels_train1.shape)\n",
    "print(\"Y Test shape: \", labels_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22631e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 115, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 115, 64)           6208      \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 115, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 58, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 58, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 7424)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               1900800   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 2,067,528\n",
      "Trainable params: 2,067,528\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(None, 115, 1) <dtype: 'float32'>\n",
      "(None, 8) <dtype: 'float32'>\n",
      "conv1d_6 (None, 115, 1) float32\n",
      "conv1d_7 (None, 115, 32) float32\n",
      "conv1d_8 (None, 115, 64) float32\n",
      "max_pooling1d_2 (None, 115, 128) float32\n",
      "dropout_2 (None, 58, 128) float32\n",
      "flatten_2 (None, 58, 128) float32\n",
      "dense_6 (None, 7424) float32\n",
      "dense_7 (None, 256) float32\n",
      "dense_8 (None, 512) float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Create sequential model \n",
    "cnn_model = tf.keras.models.Sequential()\n",
    "\n",
    "#First CNN layer  with 32 filters, conv window 3, relu activation and same padding\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001), input_shape = (X_train.shape[1],1)))\n",
    "\n",
    "#Second CNN layer  with 64 filters, conv window 3, relu activation and same padding\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "\n",
    "#Third CNN layer with 128 filters, conv window 3, relu activation and same padding\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "\n",
    "#Fourth CNN layer with Max pooling\n",
    "cnn_model.add(MaxPool1D(pool_size=(3,), strides=2, padding='same'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "\n",
    "#Flatten the output\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "#Add a dense layer with 256 neurons\n",
    "cnn_model.add(Dense(units = 256, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "\n",
    "#Add a dense layer with 512 neurons\n",
    "cnn_model.add(Dense(units = 512, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n",
    "\n",
    "#Softmax as last layer with five outputs\n",
    "cnn_model.add(Dense(units = 8, activation='softmax'))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.summary()\n",
    "\n",
    "\n",
    "[print(i.shape, i.dtype) for i in cnn_model.inputs]\n",
    "[print(o.shape, o.dtype) for o in cnn_model.outputs]\n",
    "[print(l.name, l.input_shape, l.dtype) for l in cnn_model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b685415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(X_train), type(X_test), type(labels_train), type(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6391a139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train shape:  (3687, 115, 1)\n",
      "X Test shape:  (1269, 115, 1)\n",
      "Y Train shape:  (3687, 8)\n",
      "Y Test shape:  (1269, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"X Train shape: \", X_train.shape)\n",
    "print(\"X Test shape: \", X_test.shape)\n",
    "print(\"Y Train shape: \", labels_train1.shape)\n",
    "print(\"Y Test shape: \", labels_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3d0bc1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "369/369 [==============================] - 3s 9ms/step - loss: 10349.2598 - accuracy: 0.4185 - val_loss: 933.1942 - val_accuracy: 0.2908\n",
      "Epoch 2/10\n",
      "369/369 [==============================] - 3s 8ms/step - loss: 147.1052 - accuracy: 0.5359 - val_loss: 114.8265 - val_accuracy: 0.3436\n",
      "Epoch 3/10\n",
      "369/369 [==============================] - 3s 8ms/step - loss: 35.0284 - accuracy: 0.5842 - val_loss: 119.0517 - val_accuracy: 0.2971\n",
      "Epoch 4/10\n",
      "369/369 [==============================] - 3s 8ms/step - loss: 22.4909 - accuracy: 0.6178 - val_loss: 14.1130 - val_accuracy: 0.4515\n",
      "Epoch 5/10\n",
      "369/369 [==============================] - 3s 8ms/step - loss: 21.9607 - accuracy: 0.6352 - val_loss: 15.5707 - val_accuracy: 0.3727\n",
      "Epoch 6/10\n",
      "369/369 [==============================] - 3s 8ms/step - loss: 11.3835 - accuracy: 0.6607 - val_loss: 17.1000 - val_accuracy: 0.5091\n",
      "Epoch 7/10\n",
      "369/369 [==============================] - 3s 8ms/step - loss: 15.2869 - accuracy: 0.6637 - val_loss: 18.6106 - val_accuracy: 0.5091\n",
      "Epoch 8/10\n",
      "369/369 [==============================] - 3s 8ms/step - loss: 15.5061 - accuracy: 0.6604 - val_loss: 18.1052 - val_accuracy: 0.4783\n",
      "Epoch 9/10\n",
      "369/369 [==============================] - 3s 8ms/step - loss: 10.4666 - accuracy: 0.6819 - val_loss: 14.4607 - val_accuracy: 0.4909\n",
      "Epoch 10/10\n",
      "369/369 [==============================] - 3s 8ms/step - loss: 42.2049 - accuracy: 0.6222 - val_loss: 23.3676 - val_accuracy: 0.4957\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cnn_model_history = cnn_model.fit(X_train, labels_train1, epochs=10, batch_size =10, validation_data = (X_test, labels_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73baa2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mag_1     mag_2     mag_3     mag_4     mag_5     mag_6     mag_7  \\\n",
      "0     0.265739  0.256914  0.238871  0.204497  0.183374  0.212214  0.244017   \n",
      "1     0.126638  0.063612  0.041273  0.050787  0.060859  0.076889  0.067438   \n",
      "2     0.074331  0.042567  0.033469  0.047282  0.054843  0.064086  0.074341   \n",
      "3     0.059915  0.051223  0.044134  0.036096  0.034211  0.040493  0.040402   \n",
      "4     0.009380  0.005115  0.017383  0.015676  0.014560  0.037761  0.094945   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2157  0.287983  0.239614  0.209854  0.181102  0.164073  0.191248  0.221496   \n",
      "2158  0.129129  0.117114  0.112617  0.108116  0.110345  0.141989  0.174905   \n",
      "2159  0.297354  0.237052  0.185462  0.152254  0.140301  0.168356  0.198901   \n",
      "2160  0.196470  0.169514  0.152267  0.134577  0.124661  0.147093  0.170851   \n",
      "2161  0.292884  0.253282  0.222732  0.200584  0.200503  0.259909  0.322702   \n",
      "\n",
      "         mag_8     mag_9    mag_10  ...   mag_493   mag_494   mag_495  \\\n",
      "0     0.270322  0.241667  0.244714  ...  0.177693  0.101413  0.047730   \n",
      "1     0.047884  0.022487  0.014918  ...  0.038617  0.038532  0.029333   \n",
      "2     0.080385  0.077601  0.089682  ...  0.074950  0.061139  0.063550   \n",
      "3     0.040209  0.045557  0.058400  ...  0.002198  0.005624  0.011659   \n",
      "4     0.138455  0.130802  0.111539  ...  0.069950  0.056171  0.063321   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2157  0.249034  0.223716  0.215298  ...  0.102798  0.078374  0.080415   \n",
      "2158  0.201326  0.179670  0.170672  ...  0.221865  0.177014  0.177445   \n",
      "2159  0.225881  0.209218  0.215588  ...  0.196581  0.150541  0.151612   \n",
      "2160  0.190234  0.166930  0.156963  ...  0.157541  0.131936  0.145671   \n",
      "2161  0.362787  0.303066  0.259426  ...  0.175841  0.151296  0.170315   \n",
      "\n",
      "       mag_496   mag_497   mag_498   mag_499   mag_500    name    activity  \n",
      "0     0.055375  0.173566  0.252127  0.178366  0.148060   karol  downstairs  \n",
      "1     0.056244  0.075426  0.078247  0.065877  0.076159   karol  downstairs  \n",
      "2     0.042444  0.030385  0.016828  0.016744  0.042866   karol  downstairs  \n",
      "3     0.015238  0.016284  0.012956  0.011287  0.012326   karol  downstairs  \n",
      "4     0.079940  0.108805  0.119693  0.096210  0.112591   karol  downstairs  \n",
      "...        ...       ...       ...       ...       ...     ...         ...  \n",
      "2157  0.088126  0.103586  0.098664  0.078491  0.099228  wiktor     walking  \n",
      "2158  0.190307  0.213598  0.205722  0.173344  0.236482  wiktor     walking  \n",
      "2159  0.165121  0.188219  0.173101  0.131441  0.159511  wiktor     walking  \n",
      "2160  0.173773  0.217158  0.218553  0.179803  0.230617  wiktor     walking  \n",
      "2161  0.202021  0.240609  0.223764  0.166183  0.192213  wiktor     walking  \n",
      "\n",
      "[2162 rows x 502 columns]\n"
     ]
    }
   ],
   "source": [
    "da = pd.read_csv('merged_data_normalized.csv')\n",
    "print(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae3a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
